{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Tutorial: X-ray image processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This tutorial demonstrates how to read and process X-ray images with NumPy, imageio, matplotlib and SciPy. You will learn how to read medical images, focus on certain parts, and visually compare them using mask filters and the [Sobel](https://en.wikipedia.org/wiki/Sobel_operator) and [Canny](https://en.wikipedia.org/wiki/Canny_edge_detector) edge detectors. X-ray image analysis can be part of your data analysis and [machine learning workflow](https://www.sciencedirect.com/science/article/pii/S235291481930214X) when, for example, you're building an algorithm that helps [detect pneumonia](https://www.kaggle.com/c/rsna-pneumonia-detection-challenge) as part of a [Kaggle](https://www.kaggle.com) competition. In the healthcare industry, medical image processing and analysis is particularly important when images are estimated to account for [at least 90%](https://www-03.ibm.com/press/us/en/pressrelease/51146.wss) of all medical data.\n",
        "\n",
        "You'll be working with radiology images from the [ChestX-ray8](https://www.nih.gov/news-events/news-releases/nih-clinical-center-provides-one-largest-publicly-available-chest-x-ray-datasets-scientific-community\n",
        ") dataset provided by the [National Institutes of Health (NIH)](http://nih.gov). ChestX-ray8 contains over 100,000 de-identified X-ray images in the PNG format from more than 30,000 patients. You can find ChestX-ray8's files on NIH's public Box [repository](https://nihcc.app.box.com/v/ChestXray-NIHCC) in the [`/images`](https://nihcc.app.box.com/v/ChestXray-NIHCC/folder/37178474737) folder. (For more details, refer to the research [paper](http://openaccess.thecvf.com/content_cvpr_2017/papers/Wang_ChestX-ray8_Hospital-Scale_Chest_CVPR_2017_paper.pdf) published at CVPR — a computer vision conference — in 2017.)\n",
        "\n",
        "For your convenience, a small number of PNG images have been saved to this tutorial's repository under `/biomedical-images`, since ChestX-ray8 contains gigabytes of data and you may find it challenging to download it in batches.\n",
        "\n",
        "<center><img src=\"tutorial-x-ray-image-processing.png\", width=\"1000\", hspace=\"20\" vspace=\"20\"></center>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Prerequisites"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The reader should have some knowledge of Python, NumPy arrays, and matplotlib. To refresh the memory, you can take the [Python](https://docs.python.org/dev/tutorial/index.html) and matplotlib [PyPlot](https://matplotlib.org/tutorials/introductory/pyplot.html) tutorials, and the NumPy [quickstart](https://numpy.org/devdocs/user/quickstart.html). You can also refer to Scipy Lecture Notes' [Image manipulation and processing using Numpy and Scipy](https://scipy-lectures.org/advanced/image_processing/index.html) tutorial.\n",
        "\n",
        "The following packages are used in this tutorial:\n",
        "\n",
        "- [imageio](https://imageio.github.io) for reading and writing image data. The healthcare industry usually works with the [DICOM](https://en.wikipedia.org/wiki/DICOM) format for medical imaging and [imageio](https://imageio.readthedocs.io/en/stable/format_dicom.html) should be well-suited for reading that format. In this tutorial, however, you'll be working with PNG files.\n",
        "- [matplotlib](https://matplotlib.org/) for data visualization.\n",
        "- [SciPy](https://www.scipy.org) for multi-dimensional image processing via [`ndimage`](https://docs.scipy.org/doc/scipy/reference/ndimage.html).\n",
        "\n",
        "This tutorial can be run locally in an isolated environment, such as [Virtualenv](https://virtualenv.pypa.io/en/stable/) or [conda](https://docs.conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html). You can use [Jupyter Notebook or JupyterLab](https://jupyter.org/install) to run each notebook cell. Don't forget to set up [NumPy](https://numpy.org/doc/stable/user/absolute_beginners.html#installing-numpy), [matplotlib](https://matplotlib.org/users/installing.html#installing-an-official-release), [imageio](https://imageio.readthedocs.io/en/stable/installation.html), and [SciPy](https://scipy.org/install.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Table of contents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. Examine an X-ray with `imageio`\n",
        "2. Combine images with `np.stack()` to demonstrate progression\n",
        "3. Edge detection using the Sobel and Canny filters and the Pythagorean theorem with `np.hypot()`\n",
        "4. Apply masks to X-rays with `np.where()`\n",
        "5. Compare the results\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Examine an X-ray with `imageio`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's begin with a simple example using just one X-ray image from the ChestX-ray8 dataset. \n",
        "\n",
        "The file — `00000011_001.png` — has been downloaded for you and saved in the `/biomedical-images` folder. \n",
        "\n",
        "> If you want to use your own samples, you can use [this one](https://openi.nlm.nih.gov/detailedresult?img=CXR3666_IM-1824-1001&query=chest%20infection&it=xg&req=4&npos=32) or search for various images on the [_Openi_](https://openi.nlm.nih.gov) database. Openi contains many biomedical images and it can be especially helpful if you have low bandwidth and/or are restricted by the amount of data you can download.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. Read the image with `imageio`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import imageio\n",
        "\n",
        "DIR = 'tutorial-x-ray-image-processing/'\n",
        "\n",
        "xray_image = imageio.imread(DIR + '00000011_001.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2. Check that its shape is 1024x1024 and that the array is made up of 8-bit integers:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(xray_image.shape)\n",
        "print(xray_image.dtype)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "3. Import `matplotlib` and display the image in a grayscale colormap:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.imshow(xray_image, cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Combine images with `np.stack()` to demonstrate progression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "With NumPy's `np.stack()` you can combine multiple X-rays to make an n-dimensional array and then show the \"health progress\" in a sequential manner.\n",
        "\n",
        "In the next example, instead of 1 image you'll use 8 X-ray 1024x1024-pixel images from the ChestX-ray8 dataset that have been downloaded and extracted from one of the dataset files. They are numbered from `...000.png` to `...008.png` and let's assume they belong to the same patient."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. Import NumPy and read in each of the X-rays:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "file1 = imageio.imread(DIR + '00000011_000.png')\n",
        "file2 = imageio.imread(DIR + '00000011_001.png')\n",
        "file3 = imageio.imread(DIR + '00000011_003.png')\n",
        "file4 = imageio.imread(DIR + '00000011_004.png')\n",
        "file5 = imageio.imread(DIR + '00000011_005.png')\n",
        "file6 = imageio.imread(DIR + '00000011_006.png')\n",
        "file7 = imageio.imread(DIR + '00000011_007.png')\n",
        "file8 = imageio.imread(DIR + '00000011_008.png')\n",
        "\n",
        "combined_xray_images_1 = np.stack([file1, \n",
        "                                   file2, \n",
        "                                   file3, \n",
        "                                   file4, \n",
        "                                   file5, \n",
        "                                   file6, \n",
        "                                   file7, \n",
        "                                   file8])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Alternatively, you can append the image arrays as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "combined_xray_images_2 = []\n",
        "\n",
        "for i in range(8):\n",
        "    single_xray_image = imageio.imread(DIR + '00000011_00'+str(i)+'.png')\n",
        "    combined_xray_images_2.append(single_xray_image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2. Check the shape of the new X-ray image array containing 8 stacked images:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "combined_xray_images_1.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "3. You can now display the \"health progress\" by plotting each of frames next to each other using matplotlib:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(nrows=1, ncols=8, figsize=(30, 30))\n",
        "\n",
        "for i in range(8):\n",
        "    x = combined_xray_images_1[i]\n",
        "    axes[i].imshow(x, cmap='gray')\n",
        "    axes[i].axis('off')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "4. In addition, it can be helpful to show the progress as an animation. Let's create a GIF file with `imageio.mimwrite()` and display the result in the notebook:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from IPython.display import Image\n",
        "\n",
        "GIF_PATH = DIR + 'xray_image.gif'\n",
        "imageio.mimwrite(GIF_PATH, combined_xray_images_1, format= '.gif', fps = 1) \n",
        "\n",
        "Image(filename=GIF_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Edge detection using the Sobel and Canny filters and the Pythagorean theorem with `np.hypot()`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "When processing biomedical data, it can be useful to emphasize the 2D \"edges\" to focus on particular features in an image."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### The Sobel-Feldman operator (the Sober filter)\n",
        "\n",
        "To find regions of high spatial frequency (the edges or the edge maps) along the horizontal and vertical axes of a 2D X-ray image, you can use the [Sobel-Feldman operator (Sober filter)](https://en.wikipedia.org/wiki/Sobel_operator) technique. The Sobel filter applies two 3x3 kernel matrices — one for each axis — onto the X-ray through a [convolution](https://en.wikipedia.org/wiki/Kernel_(image_processing)#Convolution). Then, these two points (gradients) are combined using the [Pythagorean theorem](https://en.wikipedia.org/wiki/Pythagorean_theorem) to produce a gradient magnitude."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. Import the `ndimage` module from SciPy and use the Sobel filters (`scipy.ndimage.sobel()`) on x- and y-axes of the X-ray. Then, calculate the distance between `x` and `y` (with the Sobel filters applied to them) using the Pythagorean theorem and NumPy's `np.hypot()` (the equivalent of `np.sqrt(np.square(x) + np.square(y))`) to obtain the magnitude. Finally, normalize the rescaled image for the pixel values to be between 0 and 255."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from scipy import ndimage\n",
        "\n",
        "x_sobel = ndimage.sobel(xray_image, axis=0)\n",
        "y_sobel = ndimage.sobel(xray_image, axis=1)\n",
        "\n",
        "xray_image_sobel = np.hypot(x_sobel, y_sobel)\n",
        "\n",
        "xray_image_sobel *= 255.0 / np.max(xray_image_sobel)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2. Check the data type of the new image array and change it to the 32-bit floating-point format to make it work with matplotlib:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print('The data type - before: ', xray_image_sobel.dtype)\n",
        "\n",
        "xray_image_sobel = xray_image_sobel.astype('float32')\n",
        "\n",
        "print('The data type - after: ', xray_image_sobel.dtype)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "3. Display the original X-ray and the one with the Sobel \"edge\" filter applied. Note that both the grayscale and `CMRmap` colormaps are used to help emphasize the edges:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(15, 15))\n",
        "\n",
        "axes[0].set_title('Original')\n",
        "axes[0].imshow(xray_image, cmap='gray')\n",
        "axes[1].set_title('Sobel (edges) - grayscale)')\n",
        "axes[1].imshow(xray_image_sobel, cmap='gray')\n",
        "axes[2].set_title('Sobel (edges) - CMRmap')\n",
        "axes[2].imshow(xray_image_sobel, cmap='CMRmap')\n",
        "for i in axes:\n",
        "    i.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### The Canny filter\n",
        "\n",
        "You can also consider using another well-known filter for edge detection called the [Canny filter](https://en.wikipedia.org/wiki/Canny_edge_detector).\n",
        "\n",
        "First, you apply a [Gaussian](https://en.wikipedia.org/wiki/Gaussian_filter) filter to remove the noise in an image. In this example, you're using using the [Fourier](https://en.wikipedia.org/wiki/Fourier_transform) filter which smoothens the X-ray through a [convolution](https://en.wikipedia.org/wiki/Convolution) process. Next, you apply the [Prewitt filter](https://en.wikipedia.org/wiki/Prewitt_operator) on each of the 2 axes of the image to help detect some of the edges — this will result in 2 gradient values. Similar to the Sobel filter, the Prewitt operator also applies two 3x3 kernel matrices — one for each axis — onto the X-ray through a [convolution](https://en.wikipedia.org/wiki/Kernel_(image_processing)#Convolution). In the end, you compute the magnitude between the two gradients using the [Pythagorean theorem](https://en.wikipedia.org/wiki/Pythagorean_theorem), as before."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. Use SciPy's Fourier filters — `scipy.ndimage.fourier_gaussian()` with a small sigma value to remove some of the noise from teh X-ray. Then, you calculate two gradients using `scipy.ndimage.prewitt()`. Next, calculate the distance between the gradients using NumPy's `np.hypot()`. To finalize the process, normalize the rescaled image for the pixel values to be between 0 and 255."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fourier_gaussian = ndimage.fourier_gaussian(xray_image, sigma=0.05)\n",
        "\n",
        "x_prewitt = ndimage.prewitt(fourier_gaussian, axis=0)\n",
        "y_prewitt = ndimage.prewitt(fourier_gaussian, axis=1)\n",
        "\n",
        "xray_image_canny = np.hypot(x_prewitt, y_prewitt)\n",
        "\n",
        "xray_image_canny *= 255.0 / np.max(xray_image_canny)\n",
        "\n",
        "print('The data type - ', xray_image_canny.dtype)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2. Plot the original X-ray image and the ones with the edges detected with the help of the Canny filter technique. The edges can be emphasized using the `prism`, `nipy_spectral`, and `terrain` matplotlib colormaps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(nrows=1, ncols=4, figsize=(20, 15))\n",
        "\n",
        "axes[0].set_title('Original')\n",
        "axes[0].imshow(xray_image, cmap='gray')\n",
        "axes[1].set_title('Canny (edges) - prism')\n",
        "axes[1].imshow(xray_image_canny, cmap='prism')\n",
        "axes[2].set_title('Canny (edges) - nipy_spectral')\n",
        "axes[2].imshow(xray_image_canny, cmap='nipy_spectral')\n",
        "axes[3].set_title('Canny (edges) - terrain')\n",
        "axes[3].imshow(xray_image_canny, cmap='terrain')\n",
        "for i in axes:\n",
        "    i.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Apply masks to X-rays with `np.where()`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To screen out only certain pixels in X-ray images to help detect particular features, you can apply masks with NumPy's `np.where(condition, x, y)`.\n",
        "\n",
        "Identify regions of interest — certain sets of pixels in an image — can be useful and masks serve as boolean arrays of the same shape as the original image."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. Retrieve some basics statistics about the pixel values in the original X-ray image you've been working with:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print('The data type of the X-ray image is: ', xray_image.dtype)\n",
        "print('The minimum pixel value is: ', np.min(xray_image))\n",
        "print('The maximum pixel value is: ', np.max(xray_image))\n",
        "print('The average pixel value is: ', np.mean(xray_image))\n",
        "print('The median pixel value is: ', np.median(xray_image))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2. The array data type is `uint8` and the minimum/maximum value results suggest that all 256 colors (from `0` to `255`) are used in the X-ray. Let's visualize the _pixel intensity distribution_ of the original raw X-ray image with `ndimage.histogram()` and matplotlib:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pixel_intensity_distribution = ndimage.histogram(xray_image, min=np.min(xray_image), max=np.max(xray_image), bins=256)\n",
        "\n",
        "plt.plot(pixel_intensity_distribution)\n",
        "plt.title('Pixel intensity distribution')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As the pixel intensity distribution suggests, there are many low (between around 0 and 20) to and very high (between around 200 and 240) pixel values. \n",
        "\n",
        "3. You can create different conditional masks with NumPy's `np.where()` — for example, let's have only those values of the image with the pixels exceeding a certain threshold (and 0 otherwise):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# The threshold is \"greater than 150\"\n",
        "xray_image_mask_noisy = np.where(xray_image > 150, xray_image, 0)\n",
        "\n",
        "plt.imshow(xray_image_mask_noisy, cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "xray_image_mask_less_noisy = np.where(xray_image > 150, 1, 0)\n",
        "\n",
        "plt.imshow(xray_image_mask_less_noisy, cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Compare the results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's display some of the results of processed X-ray images you've worked with so far:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(nrows=1, ncols=7, figsize=(30, 30))\n",
        "\n",
        "axes[0].set_title('Original')\n",
        "axes[0].imshow(xray_image, cmap='gray')\n",
        "axes[1].set_title('Sobel (edges) - grayscale')\n",
        "axes[1].imshow(xray_image_sobel, cmap='gray')\n",
        "axes[2].set_title('Sobel (edges) - hot')\n",
        "axes[2].imshow(xray_image_sobel, cmap='hot')\n",
        "axes[3].set_title('Canny (edges) - prism)')\n",
        "axes[3].imshow(xray_image_canny, cmap='prism')\n",
        "axes[4].set_title('Canny (edges) - nipy_spectral)')\n",
        "axes[4].imshow(xray_image_canny, cmap='nipy_spectral')\n",
        "axes[5].set_title('Mask (> 150, noisy)')\n",
        "axes[5].imshow(xray_image_mask_noisy, cmap='gray')\n",
        "axes[6].set_title('Mask (> 150, less noisy)')\n",
        "axes[6].imshow(xray_image_mask_less_noisy, cmap='gray')\n",
        "for i in axes:\n",
        "    i.axis('off')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "tutorial-x-ray-image-processing.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}